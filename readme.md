## ğŸ“š [ESTUDO] GeraÃ§Ã£o de Texto com Modelos de Linguagem Quantizados

Este Ã© um projetinho de estudo com foco em aprendizado prÃ¡tico sobre **Modelos de Linguagem (LLMs)**, **uso da GPU**, **quantizaÃ§Ã£o 4-bit**, integraÃ§Ã£o com **APIs em nuvem**, e boas prÃ¡ticas na construÃ§Ã£o de agentes inteligentes utilizando a biblioteca `langchain`.

---

### ğŸ¯ Objetivo

Explorar, estudar e testar o uso de modelos de linguagem otimizados para execuÃ§Ã£o local com **quantizaÃ§Ã£o em 4 bits**, reduzindo o consumo de memÃ³ria e permitindo o uso eficiente em mÃ¡quinas com GPUs mais modestas.  
O projeto evoluiu tambÃ©m para investigar a integraÃ§Ã£o com **modelos na nuvem via Hugging Face Endpoints**, possibilitando a execuÃ§Ã£o de modelos maiores sem sobrecarregar o hardware local.  
AlÃ©m disso, foram implementados agentes interativos com base na arquitetura **ReAct (Reasoning + Acting)**, capazes de utilizar ferramentas externas para raciocÃ­nio e tomada de decisÃ£o baseada em buscas em tempo real.

---

### ğŸ› ï¸ Tecnologias Utilizadas

- **ğŸ§  Transformers (Hugging Face)**  
  Utilizado para carregar e rodar modelos de linguagem localmente, com suporte Ã  quantizaÃ§Ã£o.

- **ğŸ“¦ Modelo Local: [`microsoft/Phi-3-mini-4k-instruct`](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)**  
  Modelo leve, recente e eficiente, otimizado para tarefas de instruÃ§Ã£o.

- **ğŸ§® QuantizaÃ§Ã£o com BitsAndBytesConfig**  
  Reduz o uso de memÃ³ria via `load_in_4bit=True`, viabilizando o uso de LLMs em GPUs com recursos limitados.

- **ğŸš€ CUDA (GPU)**  
  AceleraÃ§Ã£o da execuÃ§Ã£o dos modelos quantizados localmente.

- **ğŸ§© LangChain**  
  Biblioteca principal usada para estruturar a lÃ³gica de agentes com ferramentas, prompts e LLMs.

- **ğŸ“„ LangChain Hub (Prompt ReAct)**  
  UtilizaÃ§Ã£o do prompt `hwchase17/react` para estruturar agentes baseados no padrÃ£o ReAct (Reason + Act).

- **ğŸŒ HuggingFaceEndpoint**  
  Permite rodar modelos como o Meta-Llama-3-8B-Instruct em nuvem, sem depender da capacidade local de processamento.

- **ğŸ¤– AgentExecutor e create_react_agent**  
  Orquestram a execuÃ§Ã£o do agente com ferramentas conectadas, definindo como a LLM interage com o ambiente.

- **ğŸ› ï¸ Tools (Ferramentas Integradas)**:

  - **ğŸ“š WikipediaQueryRun**  
    Busca e recuperaÃ§Ã£o de conteÃºdo da Wikipedia.
  - **ğŸ” TavilySearchResults**  
    Ferramenta integrada Ã  API da Tavily para buscas online em tempo real.
  - **ğŸ“… Tool personalizada: Data atual**  
    FunÃ§Ã£o simples que retorna a data atual como uma ferramenta acessÃ­vel ao agente.

- **ğŸ” .env + os.environ**  
  UtilizaÃ§Ã£o de variÃ¡veis de ambiente para configurar tokens da Hugging Face e Tavily de forma segura e reutilizÃ¡vel no cÃ³digo.

---
